"""
This project will provide the coordinate of the upper left and lower right corner of a bounding box drawn around the fluke of a whale.

VGG19 is used as the base model to predict the bounding box position. A simpler and smaller model should be able to perform the same task
without much penalty on accuracy.
"""

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import glob

import matplotlib.pyplot as plt

from skimage.io import imread, imshow
from skimage.transform import resize

from keras.models import Model, load_model
from keras.layers import Input, GlobalMaxPooling2D
from keras.layers.core import Flatten, Dense, Dropout
from keras.optimizers import Adam

import keras
import tensorflow as tf

import random

def load_img(SL, train=True):
    """
    Given a list of image name, return the image array in the list
    """
    
    outlst=np.zeros((len(SL), h_size, w_size, channel))
    ori_size=np.zeros((len(SL), 2))
    for n, ID in enumerate(SL):
        if train==False:
            path=TEST_PATH+ID
        else:
            path=TRAIN_PATH+ID
        img=imread(path)
        ori_size[n, :]=img.shape[:2]   
        if img.ndim==3:
            img=resize(img, (h_size, w_size, 3))
        elif img.ndim==2:
            img=resize(img, (h_size, w_size))
            img=np.expand_dims(img, axis=-1)
            img[:,:,:]=img
            
        outlst[n]=img
    return outlst, ori_size

def check_id(image):
    """
    Argument:
    image-- the name of the image
    
    Return:
    ID-- the ID of the given image name.
    """
    
    ID=train['Id'][train['Image']==image].iloc[0]
    return ID

def flip_image(img):
    """
    Flip image horizontally.
    """
    flipped=np.fliplr(img)
    return flipped

#define the input size. Since we are using VGG19 as training, we will set the size to be 224x224
h_size=224
w_size=224
channel=3

TRAIN_PATH="../input/whale-categorization-playground/train/"
TEST_PATH="../input/whale-categorization-playground/test/"

#Credit to "Michael Chmutov" for hand labling about 600 images that we can used to train our model
label=pd.read_csv('../input/bb-kaggle/bb_kaggle.csv')

#reformatting the imported table
label.rename(columns={'ystart xstart yend xend': 'coordinate'}, inplace=True)
ystart=[]
xstart=[]
yend=[]
xend=[]
for i in range (len(label)):
    a=label['coordinate'].iloc[i]
    a=a.split(' ')
    ystart.append(int(a[0]))
    xstart.append(int(a[1]))
    yend.append(int(a[2]))
    xend.append(int(a[3]))
label['ystart']=ystart
label['xstart']=xstart
label['yend']=yend
label['xend']=xend
label.head()

#define variables to store original size
ori_h=[]
ori_w=[]
ori_channel=[]
img_array=np.zeros((len(label), h_size, w_size, channel))
for n, images in enumerate(label['fn']):
    img=imread(TRAIN_PATH+images)
    ori_h.append(img.shape[0])
    ori_w.append(img.shape[1])
    _channel=img.ndim
    ori_channel.append(_channel)
    
    if _channel==3:
        img=resize(img, (h_size, w_size, channel))
    elif _channel==2:
        img=resize(img, (h_size, w_size))
        img=np.expand_dims(img, axis=-1)
        img[:,:,:]=img
    img_array[n]=img

label['original height']= ori_h
label['original width']= ori_w
label['original channel']= ori_channel
   
#Define and store y_ratio and x_ratio. these ratios are important so that we can transform the 224x224 bounding box back to its original size
y_ratio=label['original height']/h_size
x_ratio=label['original width']/w_size

t_ystart=np.rint(ystart/y_ratio)
t_xstart=np.rint(xstart/x_ratio)
t_yend=np.rint(yend/y_ratio)
t_xend=np.rint(xend/x_ratio)

label['t_ystart']=t_ystart
label['t_xstart']=t_xstart
label['t_yend']=t_yend
label['t_xend']=t_xend
y_true=np.concatenate((np.expand_dims(t_ystart.values, axis=-1), np.expand_dims(t_xstart.values, axis=-1), np.expand_dims(t_yend.values, axis=-1), np.expand_dims(t_xend.values, axis=-1)), axis=1)

label.head()

credit to "taindow" for supplying additional labeled images. we will process the images as above as well.
label2=pd.read_csv('../input/bb-label-extra/bb_labels (1).csv')

y_ratio=label2['target_size_2']/h_size
x_ratio=label2['target_size_1']/w_size

t_ystart=np.rint(label2['ymin'].values/y_ratio)
t_xstart=np.rint(label2['xmin'].values/x_ratio)
t_yend=np.rint(label2['ymax'].values/y_ratio)
t_xend=np.rint(label2['xmax'].values/x_ratio)

label2['t_ystart']=t_ystart
label2['t_xstart']=t_xstart
label2['t_yend']=t_yend
label2['t_xend']=t_xend
y2_true=np.concatenate((np.expand_dims(t_ystart, axis=-1), np.expand_dims(t_xstart, axis=-1), np.expand_dims(t_yend, axis=-1), np.expand_dims(t_xend, axis=-1)), axis=1)

label2.head()

#load all images into array. All greyscale images will be converted to 3 channels as well
img2_array=np.zeros((len(label2), h_size, w_size, channel))
for n, images in enumerate(label2['image']):
    img=imread(TRAIN_PATH+images)
    _channel=img.ndim
       
    if _channel==3:
        img=resize(img, (h_size, w_size, channel))
    elif _channel==2:
        img=resize(img, (h_size, w_size))
        img=np.expand_dims(img, axis=-1)
        img[:,:,:]=img
    img2_array[n]=img
    
#sanity check
print (img_array.shape, img2_array.shape)
print (y_true.shape, y2_true.shape)

def check_distance(y_true, y_pred):
    """
    Customize loss function
    
    Argument:
    y_true-- Ground thruth position of the top left and bottom right corner of the bouding box.
    y_pred-- Predicted position of the top left and bottom right corner of the bounding box by the model.
    
    return-- the sum of distance between the top left and bottom right of y_true and y_pred
    """
    y11, x11, y12, x12=tf.split(y_true, 4, axis=1)
    y21, x21, y22, x22=tf.split(y_pred, 4, axis=1)
    
    dist_start=tf.sqrt(tf.square(y21-y11)+tf.square(x21-x11))
    dist_end=tf.sqrt(tf.square(y22-y12)+tf.square(x22-x12))
    sum_dist=dist_start+dist_end
    return sum_dist
    
def get_base_model():
    base_model=keras.applications.vgg19.VGG19(include_top=False, weights=None)
    base_model.load_weights('../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')

    x=base_model.output
    x=GlobalMaxPooling2D()(x)
    x=Dropout(0.05)(x)
    dense_1=Dense(100)(x)
    dense_1=Dense(50)(dense_1)
    dense_1=Dense(10)(dense_1)
    base_output=Dense(4)(dense_1)
    base_model=Model(base_model.input, base_output)
    return base_model
    
in_dims=(h_size, w_size, channel)
inputs=Input(in_dims)
base_model=get_base_model()
outputs=base_model(inputs)

model=Model(inputs=inputs, outputs=outputs)
model.compile(loss=check_distance, optimizer=Adam(0.00001))
print (model.summary())

#concatenate all image array from both sources
all_img=np.concatenate([img_array, img2_array], axis=0)
all_y=np.concatenate([y_true, y2_true], axis=0)

model.fit(all_img, all_y, batch_size=32, epochs=20, validation_split=0.2)

def crop_image(img_name, ystart, xstart, yend, xend, train=True):
    """
    Given an image name, load the image array and crop the image with bounding box predicted by the model
    """
    if train:
        path=TRAIN_PATH+img_name
    else:
        path=TEST_PATH+img_name
    
    img_array=imread(path)
    if img_array.ndim==3:
        img_array=img_array[ystart:yend, xstart:xend, :]
        
        img_array=resize(img_array, (h_size, w_size, channel))
    else:
        img_array=img_array[ystart:ystop, xstart:xstop]
        img_array=np.expand_dims(img_array, axis=-1)
        img_array[:,:,:]=img_array
    return img_array
    
    #drawing bounding box of all train images
all_train_img_path=glob.glob('../input/whale-categorization-playground/train/*.jpg')
all_train_img_name=[] 
for file in all_train_img_path: 
    all_train_img_name.append(file.split('/')[-1])

_batch=2000 
num_batch=int(len(all_train_img_name)/_batch)
indexes=list(range(num_batch))
all_coordinateFrame=pd.DataFrame()
for i in indexes:
    print (f'Cropping image batch {i+1} of {indexes[-1]+1}')
    coordinateFrame=pd.DataFrame() 
    if i!=indexes[-1]:
        img_array, ori_size=load_img(all_train_img_name[i*_batch:(i+1)*_batch])
        coordinateFrame['image']=all_train_img_name[i*_batch:(i+1)*_batch]

    else: 
        img_array, ori_size=load_img(all_train_img_name[i*_batch:])
        coordinateFrame['image']=all_train_img_name[i*_batch:]

    coordinate=np.rint(model.predict(img_array))
    coordinateFrame['ori height']=ori_size[:, 0] 
    coordinateFrame['ori width']=ori_size[:, 1]
    
    y_ratio=coordinateFrame['ori height']/h_size
    x_ratio=coordinateFrame['ori width']/w_size
    
    coordinateFrame['ystart']=coordinate[:, 0] 
    coordinateFrame['xstart']=coordinate[:, 1] 
    coordinateFrame['yend']=coordinate[:,2] 
    coordinateFrame['xend']=coordinate[:,3] 
    coordinateFrame['xstart'][coordinateFrame['xstart']<0]=0 
    coordinateFrame['ystart'][coordinateFrame['ystart']<0]=0
    all_coordinateFrame=pd.concat([all_coordinateFrame, coordinateFrame], axis=0, ignore_index=True)
all_coordinateFrame.head()
all_coordinateFrame.to_csv('whale_train_crop_table.csv')

#Find bounding box of test images
all_test_img_path=glob.glob('../input/whale-categorization-playground/test/*.jpg')
all_test_img_name=[]
for file in all_test_img_path:
    all_test_img_name.append(file.split('/')[-1])

_batch=2000
num_batch=int(len(all_test_img_name)/_batch)
indexes=np.arange(num_batch+1)
all_coordinateFrame=pd.DataFrame()
for i in indexes:
    print (f'Cropping image batch {i+1} of {indexes[-1]+1}')
    coordinateFrame=pd.DataFrame() 
    if i!=indexes[-1]:
        img_array, ori_size=load_img(all_test_img_name[i*_batch:(i+1)*_batch], train=False)
        coordinateFrame['image']=all_test_img_name[i*_batch:(i+1)*_batch]
    else:
        img_array, ori_size=load_img(all_test_img_name[i*_batch:], train=False)
        coordinateFrame['image']=all_test_img_name[i*_batch:]

    coordinate=np.rint(model.predict(img_array))
    coordinateFrame['ori height']=ori_size[:, 0]
    coordinateFrame['ori width']=ori_size[:, 1]
    coordinateFrame['ystart']=coordinate[:, 0]
    coordinateFrame['xstart']=coordinate[:, 1]
    coordinateFrame['yend']=coordinate[:,2]
    coordinateFrame['xend']=coordinate[:,3] 
    coordinateFrame['xstart'][coordinateFrame['xstart']<0]=0
    coordinateFrame['ystart'][coordinateFrame['ystart']<0]=0

    y_ratio=coordinateFrame['ori height']/h_size
    x_ratio=coordinateFrame['ori width']/w_size

    coordinateFrame['new ystart']=np.rint(coordinateFrame['ystart']*y_ratio)
    coordinateFrame['new xstart']=np.rint(coordinateFrame['xstart']*x_ratio)
    coordinateFrame['new yend']=np.rint(coordinateFrame['yend']*y_ratio)
    coordinateFrame['new xend']=np.rint(coordinateFrame['xend']*x_ratio)
    all_coordinateFrame=pd.concat([all_coordinateFrame, coordinateFrame], axis=0, ignore_index=True)
all_coordinateFrame.head()
all_coordinateFrame.to_csv('whale_test_crop_table.csv') 
